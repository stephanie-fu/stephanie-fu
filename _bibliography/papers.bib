---
---
@misc{bonnen2024evaluatingmultiviewobjectconsistency,
  title={Evaluating Multiview Object Consistency in Humans and Image Models},
  author={Tyler Bonnen and Stephanie Fu and Yutong Bai and Thomas O'Connell and Yoni Friedman and Nancy Kanwisher and Joshua B. Tenenbaum and Alexei A. Efros},
  year={2024},
  eprint={2409.05862},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2409.05862},
}

@misc{sharma2024visioncheckuplanguagemodels,
  title={A Vision Check-up for Language Models},
  author={Pratyusha Sharma and Tamar Rott Shaham and Manel Baradad and Stephanie Fu and Adrian Rodriguez-Munoz and Shivam Duggal and Phillip Isola and Antonio Torralba},
  year={2024},
  eprint={2401.01862},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2401.01862},
}

@misc{astruc2024openstreetview5mroadsglobalvisual,
  title={OpenStreetView-5M: The Many Roads to Global Visual Geolocation},
  author={Guillaume Astruc and Nicolas Dufour and Ioannis Siglidis and Constantin Aronssohn and Nacim Bouia and Stephanie Fu and Romain Loiseau and Van Nguyen Nguyen and Charles Raude and Elliot Vincent and Lintao XU and Hongyu Zhou and Loic Landrieu},
  year={2024},
  eprint={2404.18873},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2404.18873},
}

@misc{fu2024featupmodelagnosticframeworkfeatures,
  title={FeatUp: A Model-Agnostic Framework for Features at Any Resolution},
  author={Stephanie Fu and Mark Hamilton and Laura Brandt and Axel Feldman and Zhoutong Zhang and William T. Freeman},
  year={2024},
  eprint={2403.10516},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2403.10516},
}

@article{fu2023learning,
  title={DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data},
  author={Stephanie Fu* and Netanel Tamir* and Shobhita Sundaram* and Lucy Chai and Richard Zhang and Tali Dekel and Phillip Isola},
  journal={arXiv:2306.09344},
  year={2023},
  preview={dreamsim_icon.png},
  paper = {https://arxiv.org/abs/2306.09344},
  website = {https://dreamsim-nights.github.io},
  abstract = {Current perceptual similarity metrics operate at the level of pixels and patches. These metrics compare images in terms of their low-level colors and textures, but fail to capture mid-level similarities and differences in image layout, object pose, and semantic content. In this paper, we develop a perceptual metric that assesses images holistically. Our first step is to collect a new dataset of human similarity judgments over image pairs that are alike in diverse ways. Critical to this dataset is that judgments are nearly automatic and shared by all observers. To achieve this we use recent text-to-image models to create synthetic pairs that are perturbed along various dimensions. We observe that popular perceptual metrics fall short of explaining our new data, and we introduce a new metric, DreamSim, tuned to better align with human perception. We analyze how our metric is affected by different visual attributes, and find that it focuses heavily on foreground objects and semantic content while also being sensitive to color and layout. Notably, despite being trained on synthetic data, our metric generalizes to real images, giving strong results on retrieval and reconstruction tasks. Furthermore, our metric outperforms both prior learned metrics and recent large vision models on these tasks.},
  selected=true,
  code = {https://github.com/ssundaram21/dreamsim}
}

@article{hamilton2021axiomatic,
  title={Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning},
  author={Hamilton, Mark and Lundberg, Scott and Zhang, Lei and Fu, Stephanie and Freeman, William T},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021},
  abbr={ICLR},
  preview={expl_icon.png},
  paper = {https://arxiv.org/abs/2103.00370},
  abstract = {Visual search, recommendation, and contrastive similarity learning power technologies that impact billions of users worldwide. Modern model architectures can be complex and difficult to interpret, and there are several competing techniques one can use to explain a search engine's behavior. We show that the theory of fair credit assignment provides a unique axiomatic solution that generalizes several existing recommendation- and metric-explainability techniques in the literature. Using this formalism, we show when existing approaches violate "fairness" and derive methods that sidestep these shortcomings and naturally handle counterfactual information. More specifically, we show existing approaches implicitly approximate second-order Shapley-Taylor indices and extend CAM, GradCAM, LIME, SHAP, SBSM, and other methods to search engines. These extensions can extract pairwise correspondences between images from trained opaque-box models. We also introduce a fast kernel-based method for estimating Shapley-Taylor indices that require orders of magnitude fewer function evaluations to converge. Finally, we show that these game-theoretic measures yield more consistent explanations for image similarity architectures.},
  selected=true
}


@InProceedings{pmlr-v133-hamilton21a,
  title = 	 {MosAIc: Finding Artistic Connections across Culture with Conditional Image Retrieval},
  author =       {Hamilton, Mark and Fu, Stephanie and Lu, Mindren and Bui, Johnny and Bopp, Darius and Chen, Zhenbang and Tran, Felix and Wang, Margaret and Rogers, Marina and Zhang, Lei and Hoder, Chris and Freeman, William T.},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {133--155},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  paper = 	 {http://proceedings.mlr.press/v133/hamilton21a/hamilton21a.pdf},
  url = 	 {https://proceedings.mlr.press/v133/hamilton21a.html},
  blog={https://www.microsoft.com/en-us/garage/blog/2020/08/mit-students-build-mosaic-to-explore-art-across-cultures-at-microsoft-garage/},
  website={https://aka.ms/mosaic},
  abstract = 	 {We introduce MosAIc, an interactive web app that allows users to find pairs of semantically related artworks that span different cultures, media, and millennia. To create this application, we introduce Conditional Image Retrieval (CIR) which combines visual similarity search with user supplied filters or “conditions”. This technique allows one to find pairs of similar images that span distinct subsets of the image corpus. We provide a generic way to adapt existing image retrieval data-structures to this new domain and provide theoretical bounds on our approach’s efficiency. To quantify the performance of CIR systems, we introduce new datasets for evaluating CIR methods and show that CIR performs non-parametric style transfer. Finally, we demonstrate that our CIR data-structures can identify “blind spots” in Generative Adversarial Networks (GAN) where they fail to properly model the true data distribution.},
  abbr = {NeurIPS PMLR},
  preview = {mosaic_icon.png},
  selected=true
}

@article{Loke2021,
author={Loke, Gabriel
and Khudiyev, Tural
and Wang, Brian
and Fu, Stephanie
and Payra, Syamantak
and Shaoul, Yorai
and Fung, Johnny
and Chatziveroglou, Ioannis
and Chou, Pin-Wen
and Chinn, Itamar
and Yan, Wei
and Gitelson-Kahn, Anna
and Joannopoulos, John
and Fink, Yoel},
title={Digital electronics in fibres enable fabric-based machine-learning inference},
journal={Nature Communications},
year={2021},
month={Jun},
day={03},
volume={12},
number={1},
pages={3317},
blog={https://news.mit.edu/2021/programmable-fiber-0603},
abstract={Digital devices are the essential building blocks of any modern electronic system. Fibres containing digital devices could enable fabrics with digital system capabilities for applications in physiological monitoring, human-computer interfaces, and on-body machine-learning. Here, a scalable preform-to-fibre approach is used to produce tens of metres of flexible fibre containing hundreds of interspersed, digital temperature sensors and memory devices with a memory density of {\textasciitilde}7.6{\thinspace}{\texttimes}{\thinspace}105 bits per metre. The entire ensemble of devices are individually addressable and independently operated through a single connection at the fibre edge, overcoming the perennial single-fibre single-device limitation and increasing system reliability. The digital fibre, when incorporated within a shirt, collects and stores body temperature data over multiple days, and enables real-time inference of wearer activity with an accuracy of 96{\%} through a trained neural network with 1650 neuronal connections stored within the fibre. The ability to realise digital devices within a fibre strand which can not only measure and store physiological parameters, but also harbour the neural networks required to infer sensory data, presents intriguing opportunities for worn fabrics that sense, memorise, learn, and infer situational context.},
issn={2041-1723},
doi={10.1038/s41467-021-23628-5},
url={https://doi.org/10.1038/s41467-021-23628-5},
abbr={Nature Commun.},
paper={https://doi.org/10.1038/s41467-021-23628-5},
preview={fibers_icon.png},
selected=true
}
